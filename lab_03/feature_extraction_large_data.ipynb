{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import struct\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle_obj(file_path, obj):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pickle_obj(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def parse_mpf_file(file_path):\n",
    "    data, label = [], []\n",
    "\n",
    "    with open(file_path, 'rb') as f_object:\n",
    "        size_of_header = struct.unpack('I', f_object.read(4))[0]\n",
    "        _ = struct.unpack('8s', f_object.read(8))[0]\n",
    "        _ = f_object.read(size_of_header - 62)\n",
    "        _ = f_object.read(20)\n",
    "        code_length = struct.unpack('h', f_object.read(2))[0]\n",
    "        _ = f_object.read(20)\n",
    "        sample_number = struct.unpack('I', f_object.read(4))[0]\n",
    "        dim = struct.unpack('I', f_object.read(4))[0]\n",
    "\n",
    "        for i in range(1, sample_number):\n",
    "            sample_label = f_object.read(code_length).decode('GBK').encode('utf-8')\n",
    "            sample_data = struct.unpack(str(dim) + 'B', f_object.read(dim))\n",
    "\n",
    "            data.append(list(sample_data))\n",
    "            label.append(sample_label)\n",
    "\n",
    "    return data, label\n",
    "\n",
    "\n",
    "def read_train_set():\n",
    "    train_set_path = os.path.join(os.path.abspath('.'), 'OLHWDB1.1', 'OLHWDB1.1trn')\n",
    "\n",
    "    train_set, train_label = [], []\n",
    "    for file_name in os.listdir(train_set_path):\n",
    "        mpf_file_path = os.path.join(train_set_path, file_name)\n",
    "        mpf_data, mpf_label = parse_mpf_file(mpf_file_path)\n",
    "\n",
    "        train_set += mpf_data\n",
    "        train_label += mpf_label\n",
    "\n",
    "    file_path = os.path.join(os.path.abspath('.'), 'cached_object', 'train_set.pkl')\n",
    "    dump_pickle_obj(file_path, np.array(train_set))\n",
    "\n",
    "    file_path = os.path.join(os.path.abspath('.'), 'cached_object', 'train_label.pkl')\n",
    "    dump_pickle_obj(file_path, np.array(train_label))\n",
    "\n",
    "\n",
    "def read_test_set():\n",
    "    test_set_path = os.path.join(os.path.abspath('.'), 'OLHWDB1.1', 'OLHWDB1.1tst')\n",
    "\n",
    "    test_set, test_label = [], []\n",
    "    for file_name in os.listdir(test_set_path):\n",
    "        mpf_file_path = os.path.join(test_set_path, file_name)\n",
    "        mpf_data, mpf_label = parse_mpf_file(mpf_file_path)\n",
    "\n",
    "        test_set += mpf_data\n",
    "        test_label += mpf_label\n",
    "\n",
    "    file_path = os.path.join(os.path.abspath('.'), 'cached_object', 'test_set.pkl')\n",
    "    dump_pickle_obj(file_path, np.array(test_set))\n",
    "\n",
    "    file_path = os.path.join(os.path.abspath('.'), 'cached_object', 'test_label.pkl')\n",
    "    dump_pickle_obj(file_path, np.array(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_train_set()\n",
    "train_set = load_pickle_obj(os.path.abspath('.'), 'cached_object', 'train_set.pkl')\n",
    "train_label = load_pickle_obj(os.path.abspath('.'), 'cached_object', 'train_label.pkl')\n",
    "\n",
    "# read_test_set()\n",
    "test_set = load_pickle_obj(os.path.abspath('.'), 'cached_object', 'test_set.pkl')\n",
    "test_label = load_pickle_obj(os.path.abspath('.'), 'cached_object', 'test_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "for dim in range(10, 110, 10):\n",
    "    # PCA reduced\n",
    "    pca_model = PCA(n_components=dim)\n",
    "    pca_model.fit(train_set)\n",
    "    pca_X_train = pca_model.transform(train_set)\n",
    "    pca_X_test = pca_model.transform(test_set)\n",
    "\n",
    "    clf.fit(pca_X_train, train_label)\n",
    "    score = clf.score(pca_X_test, test_label)\n",
    "    print('PCA reduced %s, mean accuracy: %s. \\n' % (dim, score))\n",
    "    \n",
    "    # LDA reduced\n",
    "    lda_model = LinearDiscriminantAnalysis(n_components=dim)\n",
    "    lda_model.fit(train_set, train_label)\n",
    "    lda_X_train = lda_model.transform(train_set)\n",
    "    lda_X_test = lda_model.transform(test_set)\n",
    "\n",
    "    clf.fit(lda_X_train, train_label)\n",
    "    score = clf.score(lda_X_test, test_label)\n",
    "    print('LDA reduced %s, mean accuracy: %s. \\n' % (dim, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
