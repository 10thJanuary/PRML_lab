{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import euclidean_distances, check_pairwise_arrays\n",
    "from sklearn.utils.validation import check_array, check_X_y\n",
    "from sklearn.utils.extmath import safe_sparse_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_kernel(x, y=None, gamma=None):\n",
    "    x, y = check_pairwise_arrays(x, y)\n",
    "    if gamma is None:\n",
    "        gamma = 1.0 / x.shape[1]\n",
    "\n",
    "    k = euclidean_distances(x, y, squared=True)\n",
    "    k *= -gamma\n",
    "    np.exp(k, k)\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSemi(object):\n",
    "    \"\"\"Base class for semi-supervised learning model.\"\"\"\n",
    "\n",
    "    def __init__(self, gamma=20, alpha=1, max_iter=30, tol=1e-3):\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.X = None\n",
    "        self.classes = None\n",
    "        self.label_distributions = None\n",
    "        self.transduction = None\n",
    "\n",
    "    def _get_kernel(self, x, y=None):\n",
    "        if y is None:\n",
    "            return gauss_kernel(x, x, gamma=self.gamma)\n",
    "        else:\n",
    "            return gauss_kernel(x, y, gamma=self.gamma)\n",
    "\n",
    "    def _build_graph(self):\n",
    "        raise NotImplementedError(\"Graph construction must be implemented\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        probas = self.predict_proba(x)\n",
    "\n",
    "        return self.classesx[np.argmax(probas, axis=1)].ravel()\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        x_2d = check_array(x, accept_sparse=['csc', 'csr', 'coo', 'dok', 'bsr', 'lil', 'dia'])\n",
    "\n",
    "        weight_matrices = self._get_kernel(self.X, x_2d).T\n",
    "\n",
    "        probabilities = np.dot(weight_matrices, self.label_distributions)\n",
    "        normalizer = np.atleast_2d(np.sum(probabilities, axis=1)).T\n",
    "        probabilities /= normalizer\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Fit a semi-supervised model.\"\"\"\n",
    "\n",
    "        x, y = check_X_y(x, y)\n",
    "        self.X = x\n",
    "\n",
    "        # graph construction\n",
    "        graph_matrix = self._build_graph()\n",
    "\n",
    "        # label construction\n",
    "        classes = np.unique(y)\n",
    "        classes = (classes[classes != -1])\n",
    "        self.classes = classes\n",
    "\n",
    "        alpha = self.alpha\n",
    "        y = np.asarray(y)\n",
    "        unlabeled = y == -1\n",
    "\n",
    "        n_samples, n_classes = len(y), len(classes)\n",
    "        # initialize distributions\n",
    "        self.label_distributions = np.zeros((n_samples, n_classes))\n",
    "        for label in classes:\n",
    "            self.label_distributions[y == label, classes == label] = 1\n",
    "\n",
    "        y_static = np.copy(self.label_distributions)\n",
    "        if self._variant == 'GRF':\n",
    "            y_static[unlabeled] = 0\n",
    "        else:\n",
    "            y_static *= 1 - alpha\n",
    "\n",
    "        l_previous = np.zeros((self.X.shape[0], n_classes))\n",
    "\n",
    "        unlabeled = unlabeled[:, np.newaxis]\n",
    "        if sparse.isspmatrix(graph_matrix):\n",
    "            graph_matrix = graph_matrix.tocsr()\n",
    "\n",
    "        for self.n_iter_ in range(self.max_iter):\n",
    "            if np.abs(self.label_distributions - l_previous).sum() < self.tol:\n",
    "                break\n",
    "\n",
    "            l_previous = self.label_distributions\n",
    "            self.label_distributions = safe_sparse_dot(graph_matrix, self.label_distributions)\n",
    "            if self._variant == 'GRF':\n",
    "                normalizer = np.sum(self.label_distributions, axis=1)[:, np.newaxis]\n",
    "                self.label_distributions /= normalizer\n",
    "                self.label_distributions = np.where(unlabeled, self.label_distributions, y_static)\n",
    "            else:\n",
    "                self.label_distributions = np.multiply(alpha, self.label_distributions) + y_static\n",
    "        else:\n",
    "            self.n_iter_ += 1\n",
    "\n",
    "        normalizer = np.sum(self.label_distributions, axis=1)[:, np.newaxis]\n",
    "        self.label_distributions /= normalizer\n",
    "\n",
    "        # set the transduction item\n",
    "        transduction = self.classes[np.argmax(self.label_distributions, axis=1)]\n",
    "        self.transduction = transduction.ravel()\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRFSemi(BaseSemi):\n",
    "    \"\"\" References\n",
    "    Zhu, Xiaojin, Zoubin Ghahramani, and John D. Lafferty.\n",
    "    \"Semi-supervised learning using gaussian fields and harmonic functions.\"\n",
    "    Proceedings of the 20th International conference on Machine learning (ICML-03). 2003.\n",
    "    \"\"\"\n",
    "\n",
    "    _variant = 'GRF'\n",
    "\n",
    "    def __init__(self, gamma=20, alpha=None, max_iter=1000, tol=1e-3):\n",
    "        super(GRFSemi, self).__init__(gamma=gamma, alpha=alpha, max_iter=max_iter, tol=tol)\n",
    "\n",
    "    def _build_graph(self):\n",
    "        affinity_matrix = self._get_kernel(self.X)\n",
    "        normalizer = affinity_matrix.sum(axis=0)\n",
    "        if sparse.isspmatrix(affinity_matrix):\n",
    "            affinity_matrix.data /= np.diag(np.array(normalizer))\n",
    "        else:\n",
    "            affinity_matrix /= normalizer[:, np.newaxis]\n",
    "\n",
    "        return affinity_matrix\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        return super(GRFSemi, self).fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLGCSemi(BaseSemi):\n",
    "    \"\"\" References\n",
    "    Zhou, Dengyong, et al. \"Learning with local and global consistency.\"\n",
    "    Advances in neural information processing systems. 2004.\n",
    "    \"\"\"\n",
    "\n",
    "    _variant = 'LLGC'\n",
    "\n",
    "    def __init__(self, gamma=20, alpha=0.2, max_iter=30, tol=1e-3):\n",
    "        super(LLGCSemi, self).__init__(gamma=gamma, alpha=alpha, max_iter=max_iter, tol=tol)\n",
    "\n",
    "    def _build_graph(self):\n",
    "        n_samples = self.X.shape[0]\n",
    "        affinity_matrix = self._get_kernel(self.X)\n",
    "\n",
    "        laplacian = sparse.csgraph.laplacian(affinity_matrix, normed=True)\n",
    "        laplacian = -laplacian\n",
    "        if sparse.isspmatrix(laplacian):\n",
    "            diag_mask = (laplacian.row == laplacian.col)\n",
    "            laplacian.data[diag_mask] = 0.0\n",
    "        else:\n",
    "            laplacian.flat[::n_samples + 1] = 0.0\n",
    "\n",
    "        return laplacian\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        return super(LLGCSemi, self).fit(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
